<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>datasetstools. Tools for working with different datasets. &mdash; OpenCV datasetstools 3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="OpenCV datasetstools 3.0 documentation" href="index.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li><a href="index.html">OpenCV datasetstools 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="datasetstools-tools-for-working-with-different-datasets">
<h1>datasetstools. Tools for working with different datasets.<a class="headerlink" href="#datasetstools-tools-for-working-with-different-datasets" title="Permalink to this headline">¶</a></h1>
<p>The datasetstools module includes classes for working with different datasets.</p>
<p>First version of this module was implemented for <strong>Fall2014 OpenCV Challenge</strong>.</p>
<div class="section" id="action-recognition">
<h2>Action Recognition<a class="headerlink" href="#action-recognition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="ar-hmdb">
<h3>ar_hmdb<a class="headerlink" href="#ar-hmdb" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="hmdb-a-large-human-motion-database">&#8220;HMDB: A Large Human Motion Database&#8221;</span>: <a class="reference external" href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/">http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: hmdb51_org.rar &amp; test_train_splits.rar.</li>
<li>Unpack them.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_ar_hmdb -p=/home/user/path_to_unpacked_folders/</li>
</ol>
</div>
</div>
<div class="section" id="ar-sports">
<h3>ar_sports<a class="headerlink" href="#ar-sports" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="sports-1m-dataset">&#8220;Sports-1M Dataset&#8221;</span>: <a class="reference external" href="http://cs.stanford.edu/people/karpathy/deepvideo/">http://cs.stanford.edu/people/karpathy/deepvideo/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files (git clone <a class="reference external" href="https://code.google.com/p/sports-1m-dataset/">https://code.google.com/p/sports-1m-dataset/</a>).</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_ar_sports -p=/home/user/path_to_downloaded_folders/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="face-recognition">
<h2>Face Recognition<a class="headerlink" href="#face-recognition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="fr-lfw">
<h3>fr_lfw<a class="headerlink" href="#fr-lfw" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="labeled-faces-in-the-wild-a">&#8220;Labeled Faces in the Wild-a&#8221;</span>: <a class="reference external" href="http://www.openu.ac.il/home/hassner/data/lfwa/">http://www.openu.ac.il/home/hassner/data/lfwa/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset file: lfwa.tar.gz.</li>
<li>Unpack it.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_fr_lfw -p=/home/user/path_to_unpacked_folder/lfw2/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="gesture-recognition">
<h2>Gesture Recognition<a class="headerlink" href="#gesture-recognition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="gr-chalearn">
<h3>gr_chalearn<a class="headerlink" href="#gr-chalearn" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="chalearn-looking-at-people">&#8220;ChaLearn Looking at People&#8221;</span>: <a class="reference external" href="http://gesture.chalearn.org/">http://gesture.chalearn.org/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>Follow instruction from site above, download files for dataset &#8220;Track 3: Gesture Recognition&#8221;: Train1.zip-Train5.zip, Validation1.zip-Validation3.zip (Register on site: www.codalab.org and accept the terms and conditions of competition: <a class="reference external" href="https://www.codalab.org/competitions/991#learn_the_details">https://www.codalab.org/competitions/991#learn_the_details</a> There are three mirrors for downloading dataset files. When I downloaded data only mirror: &#8220;Universitat Oberta de Catalunya&#8221; works).</li>
<li>Unpack train archives Train1.zip-Train5.zip to one folder (currently loading validation files wasn&#8217;t implemented)</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_gr_chalearn -p=/home/user/path_to_unpacked_folder/</li>
</ol>
</div>
</div>
<div class="section" id="gr-skig">
<h3>gr_skig<a class="headerlink" href="#gr-skig" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="sheffield-kinect-gesture-dataset">&#8220;Sheffield Kinect Gesture Dataset&#8221;</span>: <a class="reference external" href="http://lshao.staff.shef.ac.uk/data/SheffieldKinectGesture.htm">http://lshao.staff.shef.ac.uk/data/SheffieldKinectGesture.htm</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: subject1_dep.7z-subject6_dep.7z, subject1_rgb.7z-subject6_rgb.7z.</li>
<li>Unpack them.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_gr_skig -p=/home/user/path_to_unpacked_folders/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="human-pose-estimation">
<h2>Human Pose Estimation<a class="headerlink" href="#human-pose-estimation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="hpe-parse">
<h3>hpe_parse<a class="headerlink" href="#hpe-parse" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="parse-dataset">&#8220;PARSE Dataset&#8221;</span>: <a class="reference external" href="http://www.ics.uci.edu/~dramanan/papers/parse/">http://www.ics.uci.edu/~dramanan/papers/parse/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset file: people.zip.</li>
<li>Unpack it.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_hpe_parse -p=/home/user/path_to_unpacked_folder/people_all/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="image-registration">
<h2>Image Registration<a class="headerlink" href="#image-registration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="ir-affine">
<h3>ir_affine<a class="headerlink" href="#ir-affine" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="affine-covariant-regions-datasets">&#8220;Affine Covariant Regions Datasets&#8221;</span>: <a class="reference external" href="http://www.robots.ox.ac.uk/~vgg/data/data-aff.html">http://www.robots.ox.ac.uk/~vgg/data/data-aff.html</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: bark\bikes\boat\graf\leuven\trees\ubc\wall.tar.gz.</li>
<li>Unpack them.</li>
<li>To load data, for example, for &#8220;bark&#8221;, run: ./opencv/build/bin/example_datasetstools_ir_affine -p=/home/user/path_to_unpacked_folder/bark/</li>
</ol>
</div>
</div>
<div class="section" id="ir-robot">
<h3>ir_robot<a class="headerlink" href="#ir-robot" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="robot-data-set">&#8220;Robot Data Set&#8221;</span>: <a class="reference external" href="http://roboimagedata.compute.dtu.dk/?page_id=24">http://roboimagedata.compute.dtu.dk/?page_id=24</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download files for dataset &#8220;Point Feature Data Set – 2010&#8221;: SET001_6.tar.gz-SET055_60.tar.gz (there are two data sets: - Full resolution images (1200×1600), ~500 Gb and - Half size image (600×800), ~115 Gb.)</li>
<li>Unpack them to one folder.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_ir_robot -p=/home/user/path_to_unpacked_folder/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="image-segmentation">
<h2>Image Segmentation<a class="headerlink" href="#image-segmentation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="is-bsds">
<h3>is_bsds<a class="headerlink" href="#is-bsds" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="the-berkeley-segmentation-dataset-and-benchmark">&#8220;The Berkeley Segmentation Dataset and Benchmark&#8221;</span>: <a class="reference external" href="https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/">https://www.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: BSDS300-human.tgz &amp; BSDS300-images.tgz.</li>
<li>Unpack them.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_is_bsds -p=/home/user/path_to_unpacked_folder/BSDS300/</li>
</ol>
</div>
</div>
<div class="section" id="is-weizmann">
<h3>is_weizmann<a class="headerlink" href="#is-weizmann" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="weizmann-segmentation-evaluation-database">&#8220;Weizmann Segmentation Evaluation Database&#8221;</span>: <a class="reference external" href="http://www.wisdom.weizmann.ac.il/~vision/Seg_Evaluation_DB/">http://www.wisdom.weizmann.ac.il/~vision/Seg_Evaluation_DB/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: Weizmann_Seg_DB_1obj.ZIP &amp; Weizmann_Seg_DB_2obj.ZIP.</li>
<li>Unpack them.</li>
<li>To load data, for example, for 1 object dataset, run: ./opencv/build/bin/example_datasetstools_is_weizmann -p=/home/user/path_to_unpacked_folder/1obj/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="multiview-stereo-matching">
<h2>Multiview Stereo Matching<a class="headerlink" href="#multiview-stereo-matching" title="Permalink to this headline">¶</a></h2>
<div class="section" id="msm-epfl">
<h3>msm_epfl<a class="headerlink" href="#msm-epfl" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="epfl-multi-view-stereo">&#8220;EPFL Multi-View Stereo&#8221;</span>: <a class="reference external" href="http://cvlabwww.epfl.ch/~strecha/multiview/denseMVS.html">http://cvlabwww.epfl.ch/~strecha/multiview/denseMVS.html</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: castle_dense\castle_dense_large\castle_entry\fountain\herzjesu_dense\herzjesu_dense_large_bounding\cameras\images\p.tar.gz.</li>
<li>Unpack them in separate folder for each object. For example, for &#8220;fountain&#8221;, in folder fountain/ : fountain_dense_bounding.tar.gz -&gt; bounding/, fountain_dense_cameras.tar.gz -&gt; camera/, fountain_dense_images.tar.gz -&gt; png/, fountain_dense_p.tar.gz -&gt; P/</li>
<li>To load data, for example, for &#8220;fountain&#8221;, run: ./opencv/build/bin/example_datasetstools_msm_epfl -p=/home/user/path_to_unpacked_folder/fountain/</li>
</ol>
</div>
</div>
<div class="section" id="msm-middlebury">
<h3>msm_middlebury<a class="headerlink" href="#msm-middlebury" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="stereo-middlebury-computer-vision">&#8220;Stereo – Middlebury Computer Vision&#8221;</span>: <a class="reference external" href="http://vision.middlebury.edu/mview/">http://vision.middlebury.edu/mview/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: dino\dinoRing\dinoSparseRing\temple\templeRing\templeSparseRing.zip</li>
<li>Unpack them.</li>
<li>To load data, for example &#8220;temple&#8221; dataset, run: ./opencv/build/bin/example_datasetstools_msm_middlebury -p=/home/user/path_to_unpacked_folder/temple/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="object-recognition">
<h2>Object Recognition<a class="headerlink" href="#object-recognition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="or-imagenet">
<h3>or_imagenet<a class="headerlink" href="#or-imagenet" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="imagenet">&#8220;ImageNet&#8221;</span>: <a class="reference external" href="http://www.image-net.org/">http://www.image-net.org/</a></p>
<p>Currently implemented loading full list with urls. Planned to implement dataset from ILSVRC challenge.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset file: imagenet_fall11_urls.tgz</li>
<li>Unpack it.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_or_imagenet -p=/home/user/path_to_unpacked_file/</li>
</ol>
</div>
</div>
<div class="section" id="or-sun">
<h3>or_sun<a class="headerlink" href="#or-sun" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="sun-database">&#8220;SUN Database&#8221;</span>: <a class="reference external" href="http://sun.cs.princeton.edu/">http://sun.cs.princeton.edu/</a></p>
<p>Currently implemented loading &#8220;Scene Recognition Benchmark. SUN397&#8221;. Planned to implement also &#8220;Object Detection Benchmark. SUN2012&#8221;.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset file: SUN397.tar</li>
<li>Unpack it.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_or_sun -p=/home/user/path_to_unpacked_folder/SUN397/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="slam">
<h2>SLAM<a class="headerlink" href="#slam" title="Permalink to this headline">¶</a></h2>
<div class="section" id="slam-kitti">
<h3>slam_kitti<a class="headerlink" href="#slam-kitti" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="kitti-vision-benchmark">&#8220;KITTI Vision Benchmark&#8221;</span>: <a class="reference external" href="http://www.cvlibs.net/datasets/kitti/eval_odometry.php">http://www.cvlibs.net/datasets/kitti/eval_odometry.php</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download &#8220;Odometry&#8221; dataset files: data_odometry_gray\data_odometry_color\data_odometry_velodyne\data_odometry_poses\data_odometry_calib.zip.</li>
<li>Unpack data_odometry_poses.zip, it creates folder dataset/poses/. After that unpack data_odometry_gray.zip, data_odometry_color.zip, data_odometry_velodyne.zip. Folder dataset/sequences/ will be created with folders 00/..21/. Each of these folders will contain: image_0/, image_1/, image_2/, image_3/, velodyne/ and files calib.txt &amp; times.txt. These two last files will be replaced after unpacking data_odometry_calib.zip at the end.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_slam_kitti -p=/home/user/path_to_unpacked_folder/dataset/</li>
</ol>
</div>
</div>
<div class="section" id="slam-tumindoor">
<h3>slam_tumindoor<a class="headerlink" href="#slam-tumindoor" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="tumindoor-dataset">&#8220;TUMindoor Dataset&#8221;</span>: <a class="reference external" href="http://www.navvis.lmt.ei.tum.de/dataset/">http://www.navvis.lmt.ei.tum.de/dataset/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: dslr\info\ladybug\pointcloud.tar.bz2 for each dataset: 11-11-28 (1st floor)\11-12-13 (1st floor N1)\11-12-17a (4th floor)\11-12-17b (3rd floor)\11-12-17c (Ground I)\11-12-18a (Ground II)\11-12-18b (2nd floor)</li>
<li>Unpack them in separate folder for each dataset. dslr.tar.bz2 -&gt; dslr/, info.tar.bz2 -&gt; info/, ladybug.tar.bz2 -&gt; ladybug/, pointcloud.tar.bz2 -&gt; pointcloud/.</li>
<li>To load each dataset run: ./opencv/build/bin/example_datasetstools_slam_tumindoor -p=/home/user/path_to_unpacked_folders/</li>
</ol>
</div>
</div>
</div>
<div class="section" id="text-recognition">
<h2>Text Recognition<a class="headerlink" href="#text-recognition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="tr-chars">
<h3>tr_chars<a class="headerlink" href="#tr-chars" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="the-chars74k-dataset">&#8220;The Chars74K Dataset&#8221;</span>: <a class="reference external" href="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/">http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset files: EnglishFnt\EnglishHnd\EnglishImg\KannadaHnd\KannadaImg.tgz, ListsTXT.tgz.</li>
<li>Unpack them.</li>
<li>Move <a href="#id1"><span class="problematic" id="id2">*</span></a>.m files from folder ListsTXT/ to appropriate folder. For example, English/list_English_Img.m for EnglishImg.tgz.</li>
<li>To load data, for example &#8220;EnglishImg&#8221;, run: ./opencv/build/bin/example_datasetstools_tr_chars -p=/home/user/path_to_unpacked_folder/English/</li>
</ol>
</div>
</div>
<div class="section" id="tr-svt">
<h3>tr_svt<a class="headerlink" href="#tr-svt" title="Permalink to this headline">¶</a></h3>
<p>Implements loading dataset:</p>
<p><span class="target" id="the-street-view-text-dataset">&#8220;The Street View Text Dataset&#8221;</span>: <a class="reference external" href="http://vision.ucsd.edu/~kai/svt/">http://vision.ucsd.edu/~kai/svt/</a></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Usage</p>
<ol class="last arabic simple">
<li>From link above download dataset file: svt.zip.</li>
<li>Unpack it.</li>
<li>To load data run: ./opencv/build/bin/example_datasetstools_tr_svt -p=/home/user/path_to_unpacked_folder/svt/svt1/</li>
</ol>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">datasetstools. Tools for working with different datasets.</a><ul>
<li><a class="reference internal" href="#action-recognition">Action Recognition</a><ul>
<li><a class="reference internal" href="#ar-hmdb">ar_hmdb</a></li>
<li><a class="reference internal" href="#ar-sports">ar_sports</a></li>
</ul>
</li>
<li><a class="reference internal" href="#face-recognition">Face Recognition</a><ul>
<li><a class="reference internal" href="#fr-lfw">fr_lfw</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gesture-recognition">Gesture Recognition</a><ul>
<li><a class="reference internal" href="#gr-chalearn">gr_chalearn</a></li>
<li><a class="reference internal" href="#gr-skig">gr_skig</a></li>
</ul>
</li>
<li><a class="reference internal" href="#human-pose-estimation">Human Pose Estimation</a><ul>
<li><a class="reference internal" href="#hpe-parse">hpe_parse</a></li>
</ul>
</li>
<li><a class="reference internal" href="#image-registration">Image Registration</a><ul>
<li><a class="reference internal" href="#ir-affine">ir_affine</a></li>
<li><a class="reference internal" href="#ir-robot">ir_robot</a></li>
</ul>
</li>
<li><a class="reference internal" href="#image-segmentation">Image Segmentation</a><ul>
<li><a class="reference internal" href="#is-bsds">is_bsds</a></li>
<li><a class="reference internal" href="#is-weizmann">is_weizmann</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiview-stereo-matching">Multiview Stereo Matching</a><ul>
<li><a class="reference internal" href="#msm-epfl">msm_epfl</a></li>
<li><a class="reference internal" href="#msm-middlebury">msm_middlebury</a></li>
</ul>
</li>
<li><a class="reference internal" href="#object-recognition">Object Recognition</a><ul>
<li><a class="reference internal" href="#or-imagenet">or_imagenet</a></li>
<li><a class="reference internal" href="#or-sun">or_sun</a></li>
</ul>
</li>
<li><a class="reference internal" href="#slam">SLAM</a><ul>
<li><a class="reference internal" href="#slam-kitti">slam_kitti</a></li>
<li><a class="reference internal" href="#slam-tumindoor">slam_tumindoor</a></li>
</ul>
</li>
<li><a class="reference internal" href="#text-recognition">Text Recognition</a><ul>
<li><a class="reference internal" href="#tr-chars">tr_chars</a></li>
<li><a class="reference internal" href="#tr-svt">tr_svt</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/datasetstools.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li><a href="index.html">OpenCV datasetstools 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, itseez.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>